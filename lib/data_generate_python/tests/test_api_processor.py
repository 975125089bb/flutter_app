"""
Test script for the DeepSeek data processor
This script processes a small sample to verify the API integration works
"""

import os
import sys
from pathlib import Path

# Add parent directory to Python path for imports
current_dir = Path(__file__).parent
parent_dir = current_dir.parent
sys.path.append(str(parent_dir))
sys.path.append(str(parent_dir.parent.parent.parent))  # Add root folder

# Change working directory to parent (main scripts folder) for file operations
if Path.cwd().name != "data_generate_python":
    os.chdir(parent_dir)

from deepseek_data_processor import DeepSeekProcessor, ProcessedPerson


def test_single_extraction():
    """Test the API extraction with a single sample"""

    # Sample text from your data
    sample_text = """
å‡ºç”Ÿï¼š81
èº«é«˜ï¼š180
ä½“é‡ï¼š85
æ€§åˆ«ï¼šç”·
åœ°åŒºï¼šæ¾æˆ·
å®¶ä¹¡ï¼šæ²ˆé˜³
å­¦å†ï¼šå¤§å­¦
èŒä¸šï¼šè½¯ä»¶
æ˜Ÿåº§ï¼šå¤©è
æˆ¿è½¦ï¼šæœ‰æˆ¿æ— è½¦
å©šå²ï¼šç¦»å©š
çˆ±å¥½ï¼šä¹¦æ³•ï¼Œæ‘„å½±ï¼Œæˆ·å¤–ï¼Œè¿åŠ¨ï¼ŒéŸ³ä¹ï¼Œæ—…è¡Œ
äººæ ¼ï¼šENTJ

è‡ªæˆ‘ä»‹ç»
ä½ å¥½ï¼Œæˆ‘æ˜¯ä¸€ä¸ªçœŸè¯šã€æœ‰è´£ä»»æ„Ÿ,é˜³å…‰è‡ªä¿¡çš„ç”·ç”Ÿï¼Œ81å¹´ç”Ÿï¼Œ
ç›®å‰ä»äº‹ITè¡Œä¸šï¼Œå¹³æ—¶å·¥ä½œè™½ç„¶æœ‰ç‚¹å¿™ï¼Œ
ä½†æˆ‘å§‹ç»ˆç›¸ä¿¡ç”Ÿæ´»ä¸ä»…åªæœ‰å·¥ä½œï¼Œæ›´éœ€è¦æœ‰äººä¸€èµ·åˆ†äº«å–œæ€’å“€ä¹ã€‚
æ€§æ ¼ç¨³é‡ä½†ä¸å¤±å¹½é»˜ï¼Œçˆ±å¥½å¹¿æ³›ï¼Œå–œæ¬¢äº’ç›¸å°Šé‡ï¼Œé¼“åŠ±ï¼Œæ”¯æŒçš„äº¤æµå’Œäº¤å¾€,
å¹¶å–œæ¬¢ç¾é£Ÿã€çœ‹ç”µå½±ï¼ŒåŒæ—¶äº«å—å®‰é™å®…å®¶çš„æ—¶å…‰ã€‚

æ‹©å¶è¦æ±‚
å¸Œæœ›é‡åˆ°ä¸€ä¸ªå–„è‰¯ã€çš®è‚¤ç™½å‡€ï¼Œæœ‰çˆ±å¿ƒã€æ‡‚å¾—æ²Ÿé€šçš„ä½ ï¼Œä¸éœ€è¦å®Œç¾ï¼Œ
ä½†æ„¿å½¼æ­¤æœ‰å…±åŒè¯é¢˜ï¼Œæœ‰å¿ƒèµ°è¿›å¯¹æ–¹çš„ä¸–ç•Œã€‚
ä¸¤ä¸ªäººä¸€èµ·åŠªåŠ›ã€ä¸€èµ·æˆé•¿ï¼Œæºæ‰‹èµ°è¿‡æœªæ¥çš„æ¯ä¸€ä¸ªæ˜¥å¤ç§‹å†¬ã€‚
"""

    API_KEY = "sk-d17e63eeef2d46f4bb404b2a05f125ce"

    processor = DeepSeekProcessor(
        api_key=API_KEY,
        max_requests_per_minute=5,  # Very conservative for testing
        delay_between_requests=2.0,
    )

    print("ğŸ§ª Testing single extraction...")
    print("=" * 40)

    result = processor.call_api(sample_text)

    if result:
        print("âœ… API call successful!")
        print("ğŸ“Š Extracted data:")
        for key, value in result.items():
            print(f"   {key}: {value}")

        # Test creating ProcessedPerson object
        result["id"] = "test_98"
        result["raw_text"] = sample_text

        try:
            person = ProcessedPerson(**result)
            print(f"\nâœ… ProcessedPerson created successfully!")
            print(f"   ID: {person.id}")
            print(f"   Gender: {person.gender}")
            print(f"   Age: {person.age}")
            print(f"   BMI: {person.bmi}")
            return True
        except Exception as e:
            print(f"âŒ Error creating ProcessedPerson: {e}")
            return False
    else:
        print("âŒ API call failed")
        return False


def test_small_batch():
    """Test processing a small batch from one file"""

    API_KEY = "sk-d17e63eeef2d46f4bb404b2a05f125ce"

    processor = DeepSeekProcessor(
        api_key=API_KEY, max_requests_per_minute=5, delay_between_requests=3.0
    )

    # Process just the first few entries from one file
    input_folder = Path("raw_data")
    output_file = Path("tests/test_output.csv")

    if not input_folder.exists():
        print(f"âŒ Input folder {input_folder} not found!")
        print("ğŸ’¡ Make sure you're running from the correct directory")
        return False

    print("\nğŸ”„ Testing small batch processing...")
    print("=" * 40)

    # Find a test file
    test_files = list(input_folder.glob("*.md"))
    if not test_files:
        print("âŒ No test files found!")
        return False

    # Filter out non-profile files - keep only men_*.md and women_*.md
    profile_files = [
        f
        for f in test_files
        if f.name.startswith(("men_", "women_")) and f.name.endswith(".md")
    ]

    if not profile_files:
        print("âŒ No profile files found!")
        print("ğŸ’¡ Looking for files like men_100.md, women_100.md, etc.")
        print(f"   Available files: {[f.name for f in test_files]}")
        return False

    # Sort to get consistent results
    profile_files.sort()
    test_file = profile_files[0]
    print(f"ğŸ“„ Testing with file: {test_file.name}")

    try:
        # Read and process just the first 2 entries
        with open(test_file, "r", encoding="utf-8") as f:
            content = f.read()

        person_blocks = processor.extract_person_blocks(content)
        print(f"ğŸ“Š Found {len(person_blocks)} person blocks")

        # Process only first 2 to save costs
        test_blocks = person_blocks[:2]
        print(f"ğŸ¯ Testing with first {len(test_blocks)} entries")

        processed_people = []
        for block in test_blocks:
            person_id = block["id"]
            text = block["content"]

            print(f"\nğŸ”„ Processing person {person_id}...")

            extracted_info = processor.call_api(text)

            if extracted_info:
                extracted_info["id"] = person_id
                extracted_info["raw_text"] = text

                person = ProcessedPerson(**extracted_info)
                processed_people.append(person)
                print(f"âœ… Successfully processed person {person_id}")
            else:
                print(f"âŒ Failed to extract info for person {person_id}")

        if processed_people:
            processor.save_to_csv(processed_people, output_file)
            print(
                f"\nğŸ‰ Test completed! Saved {len(processed_people)} entries to {output_file}"
            )
            return True
        else:
            print("\nâŒ No profiles processed successfully")
            return False

    except Exception as e:
        print(f"âŒ Test failed: {e}")
        return False


def main():
    """Main test function"""
    print("ğŸ§ª DeepSeek Data Processor Test Suite")
    print("=" * 50)

    success_count = 0
    total_tests = 2

    # Test 1: Single extraction
    print("\nğŸ“‹ Test 1: Single API Extraction")
    if test_single_extraction():
        success_count += 1

    # Test 2: Small batch processing
    print("\nğŸ“‹ Test 2: Small Batch Processing")
    if test_small_batch():
        success_count += 1

    # Results
    print("\n" + "=" * 50)
    print(f"ğŸ¯ Test Results: {success_count}/{total_tests} tests passed")

    if success_count == total_tests:
        print("ğŸ‰ All tests completed successfully!")
        print("\nğŸ’¡ Next steps:")
        print("   1. Run the full pipeline: python data_pipeline.py")
        print("   2. Or run batch processing: python batch_processor.py")
    else:
        print("âŒ Some tests failed. Check the error messages above.")
        print("\nğŸ’¡ Troubleshooting:")
        print("   1. Verify API key is correct")
        print("   2. Check internet connection")
        print("   3. Ensure raw_data folder exists with .md files")


if __name__ == "__main__":
    main()
