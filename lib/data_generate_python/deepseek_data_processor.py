import os
import json
import time
import re
import csv
from pathlib import Path
from typing import List, Dict, Any, Optional
from dataclasses import dataclass, asdict
import requests
from datetime import datetime


@dataclass
class ProcessedPerson:
    """Data structure for processed person information"""

    id: str
    raw_text: Optional[str] = None

    # Basic info
    gender: Optional[str] = None
    birth_year: Optional[str] = None
    age: Optional[int] = None
    zodiac: Optional[str] = None
    mbti: Optional[str] = None

    # Physical attributes
    height_cm: Optional[int] = None
    weight_kg: Optional[int] = None
    bmi: Optional[float] = None

    # Location info
    hometown: Optional[str] = None
    current_location: Optional[str] = None

    # Education & Career
    education: Optional[str] = None
    occupation: Optional[str] = None
    annual_income: Optional[str] = None

    # Lifestyle
    hobbies: Optional[str] = None
    personality: Optional[str] = None

    # Assets & Status
    has_house: Optional[bool] = None
    has_car: Optional[bool] = None
    marital_status: Optional[str] = None

    # Preferences
    partner_preferences: Optional[str] = None
    self_introduction: Optional[str] = None

    def __post_init__(self):
        """Calculate derived fields"""
        if self.height_cm and self.weight_kg:
            height_m = self.height_cm / 100
            self.bmi = round(self.weight_kg / (height_m**2), 1)

        if self.birth_year and self.birth_year.isdigit():
            current_year = datetime.now().year
            birth_year_int = int(self.birth_year)
            if birth_year_int < 100:  # Handle 2-digit years
                birth_year_int += 1900 if birth_year_int > 30 else 2000
            self.age = current_year - birth_year_int


class DeepSeekProcessor:
    """Process personal data using DeepSeek API with cost control"""

    def __init__(
        self,
        api_key: str,
        max_requests_per_minute: int = 20,
        delay_between_requests: float = 3.5,
    ):
        self.api_key = api_key
        self.base_url = "https://api.deepseek.com/v1/chat/completions"
        self.max_requests_per_minute = max_requests_per_minute
        self.delay_between_requests = delay_between_requests
        self.request_count = 0
        self.start_time = time.time()

        self.system_prompt = """
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä¸ªäººä¿¡æ¯æå–åŠ©æ‰‹ã€‚ç”¨æˆ·å°†æä¾›åŒ…å«ä¸ªäººæ¡£æ¡ˆä¿¡æ¯çš„ä¸­æ–‡æ–‡æœ¬ã€‚

è¯·ä¸¥æ ¼æŒ‰ä»¥ä¸‹JSONæ ¼å¼è¿”å›žæå–åˆ°çš„æ‰€æœ‰ä¿¡æ¯ï¼ŒæœªæåŠçš„å­—æ®µè¿”å›žnullã€‚
æ³¨æ„ï¼šæ€§åˆ«å°†ç”±ç³»ç»Ÿæ ¹æ®æ–‡ä»¶åè‡ªåŠ¨ç¡®å®šï¼Œæ— éœ€ä»Žæ–‡æœ¬ä¸­æå–ã€‚

{
    "birth_year": "å‡ºç”Ÿå¹´ä»½ï¼ˆ4ä½æ•°å­—å­—ç¬¦ä¸²ï¼Œå¦‚'1990'ï¼‰æˆ–null",
    "zodiac": "æ˜Ÿåº§æˆ–null", 
    "mbti": "MBTIæ€§æ ¼ç±»åž‹ï¼ˆ4å­—æ¯ï¼Œå¦‚'ENTJ'ï¼‰æˆ–null",
    "height_cm": "èº«é«˜åŽ˜ç±³æ•°ï¼ˆæ•´æ•°ï¼‰æˆ–null",
    "weight_kg": "ä½“é‡åƒå…‹æ•°ï¼ˆæ•´æ•°ï¼‰æˆ–null",
    "hometown": "å®¶ä¹¡/å‡ºç”Ÿåœ°æˆ–null",
    "current_location": "çŽ°å±…ä½åœ°/åœ°åŒºæˆ–null", 
    "education": "å­¦åŽ†æˆ–null",
    "occupation": "èŒä¸šæˆ–null",
    "annual_income": "å¹´æ”¶å…¥æè¿°æˆ–null",
    "hobbies": "çˆ±å¥½å…´è¶£ï¼ˆåˆå¹¶ä¸ºä¸€ä¸ªå­—ç¬¦ä¸²ï¼‰æˆ–null",
    "personality": "æ€§æ ¼æè¿°æˆ–null",
    "has_house": "æ˜¯å¦æœ‰æˆ¿ï¼ˆtrue/false/nullï¼‰",
    "has_car": "æ˜¯å¦æœ‰è½¦ï¼ˆtrue/false/nullï¼‰",
    "marital_status": "å©šå§»çŠ¶å†µæˆ–null",
    "partner_preferences": "æ‹©å¶è¦æ±‚æˆ–null",
    "self_introduction": "è‡ªæˆ‘ä»‹ç»æˆ–null"
}

æå–è§„åˆ™ï¼š
1. å¹´ä»½è½¬æ¢ï¼š81å¹´->1981å¹´ï¼Œ04å¹´->2004å¹´ï¼Œ2ä½æ•°å¹´ä»½ï¼š>30åŠ 1900ï¼Œ<=30åŠ 2000
2. å•ä½è½¬æ¢ï¼šè‡ªåŠ¨è½¬æ¢èº«é«˜ä½“é‡åˆ°åŽ˜ç±³å’Œåƒå…‹
3. æˆ¿è½¦çŠ¶æ€ï¼šä»Ž"æœ‰æˆ¿æ— è½¦"ã€"æ— æˆ¿æœ‰è½¦"ç­‰æ–‡æœ¬ä¸­æå–å¸ƒå°”å€¼
4. åˆå¹¶ç›¸ä¼¼å­—æ®µï¼šå°†æ‰€æœ‰çˆ±å¥½åˆå¹¶ä¸ºä¸€ä¸ªå­—ç¬¦ä¸²
5. åªè¿”å›žJSONï¼Œä¸è¦å…¶ä»–æ–‡å­—è¯´æ˜Ž
6. ä¸è¦æå–æ€§åˆ«ä¿¡æ¯ï¼ˆç³»ç»Ÿä¼šè‡ªåŠ¨å¤„ç†ï¼‰

ç¤ºä¾‹è¾“å…¥ï¼š"81å¹´ç”Ÿï¼Œèº«é«˜180ï¼Œä½“é‡85ï¼Œæ¾æˆ·ï¼Œæ²ˆé˜³ï¼Œå¤§å­¦ï¼Œè½¯ä»¶ï¼Œå¤©èŽï¼Œæœ‰æˆ¿æ— è½¦ï¼Œç¦»å©šï¼Œçˆ±å¥½ï¼šä¹¦æ³•ï¼Œæ‘„å½±"
ç¤ºä¾‹è¾“å‡ºï¼š{"birth_year":"1981","zodiac":"å¤©èŽ","height_cm":180,"weight_kg":85,"hometown":"æ²ˆé˜³","current_location":"æ¾æˆ·","education":"å¤§å­¦","occupation":"è½¯ä»¶","hobbies":"ä¹¦æ³•ï¼Œæ‘„å½±","has_house":true,"has_car":false,"marital_status":"ç¦»å©š"}
"""

    def rate_limit_control(self):
        """Control API request rate to avoid costs"""
        self.request_count += 1

        # Check if we've exceeded the rate limit
        elapsed_time = time.time() - self.start_time
        if elapsed_time < 60 and self.request_count >= self.max_requests_per_minute:
            sleep_time = 60 - elapsed_time
            print(f"Rate limit reached. Sleeping for {sleep_time:.1f} seconds...")
            time.sleep(sleep_time)
            self.request_count = 0
            self.start_time = time.time()

        # Delay between requests
        time.sleep(self.delay_between_requests)

    def call_api(self, text: str) -> Dict[str, Any]:
        """Make API call to DeepSeek"""
        self.rate_limit_control()

        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json",
        }

        payload = {
            "model": "deepseek-chat",
            "messages": [
                {"role": "system", "content": self.system_prompt},
                {"role": "user", "content": text},
            ],
            "temperature": 0.1,  # Low temperature for consistent extraction
            "max_tokens": 1000,
            "stream": False,
        }

        try:
            response = requests.post(
                self.base_url, headers=headers, json=payload, timeout=30
            )
            response.raise_for_status()

            result = response.json()
            content = result["choices"][0]["message"]["content"].strip()

            # Extract JSON from response
            json_match = re.search(r"\{.*\}", content, re.DOTALL)
            if json_match:
                return json.loads(json_match.group())
            else:
                print(f"No JSON found in response: {content}")
                return {}

        except requests.exceptions.RequestException as e:
            print(f"API request failed: {e}")
            return {}
        except json.JSONDecodeError as e:
            print(f"JSON decode error: {e}")
            return {}
        except Exception as e:
            print(f"Unexpected error: {e}")
            return {}

    def extract_person_blocks(self, content: str) -> List[Dict[str, str]]:
        """Extract individual person blocks from markdown content"""
        person_blocks = []

        # Split by person entries (ç¼–å·XX pattern)
        pattern = r"ç¼–å·"
        splits = re.split(pattern, content)

        # Process splits in pairs (id, content)
        for i in range(1, len(splits)):
            person_id = i
            person_content = splits[i]

            if "\n" in person_content:

                # extract the number ID
                first_line = person_content[: person_content.find("\n")]
                match = re.search(r"(\d+)", first_line)
                person_number = match.group(1) if match else "None"

                person_content = (
                    "ç¼–å·"
                    + person_number
                    + "\n"
                    + person_content[person_content.find("\n") + 1 :]
                )

            if person_content:
                person_blocks.append({"id": person_id, "content": person_content})

        return person_blocks

    def determine_gender_from_filename(self, file_path: Path) -> Optional[str]:
        """Determine gender from filename pattern"""
        filename = file_path.name.lower()
        if filename.startswith("men_"):
            return "ç”·"
        elif filename.startswith("women_"):
            return "å¥³"
        return None

    def process_file(self, file_path: Path) -> List[ProcessedPerson]:
        """Process a single data file"""
        print(f"Processing file: {file_path.name}")

        with open(file_path, "r", encoding="utf-8") as f:
            content = f.read()

        person_blocks = self.extract_person_blocks(content)
        processed_people = []

        # Determine gender from filename
        gender_from_filename = self.determine_gender_from_filename(file_path)
        if gender_from_filename:
            print(f"ðŸ“‹ Determined gender from filename: {gender_from_filename}")

        for block in person_blocks:
            person_id = block["id"]
            text = block["content"]

            print(f"Processing person {person_id}...")

            # Call API to extract information
            extracted_info = self.call_api(text)

            if extracted_info:
                # Override gender with filename-based determination
                if gender_from_filename:
                    extracted_info["gender"] = gender_from_filename
                    print(f"âœ“ Set gender from filename: {gender_from_filename}")

                # Create ProcessedPerson object
                extracted_info["id"] = person_id
                extracted_info["raw_text"] = text

                try:
                    person = ProcessedPerson(**extracted_info)
                    processed_people.append(person)
                    print(f"âœ“ Successfully processed person {person_id}")
                except TypeError as e:
                    print(f"âœ— Error creating person object for {person_id}: {e}")
                    # Create with minimal data
                    person = ProcessedPerson(
                        id=person_id, raw_text=text, gender=gender_from_filename
                    )
                    processed_people.append(person)
            else:
                print(f"âœ— Failed to extract info for person {person_id}")
                # Create with minimal data, but include gender from filename
                person = ProcessedPerson(
                    id=person_id, raw_text=text, gender=gender_from_filename
                )
                processed_people.append(person)

        return processed_people

    def process_all_files(
        self,
        input_folder: Path,
        output_file: Path,
        file_patterns: Optional[List[str]] = None,
    ) -> List[ProcessedPerson]:
        """Process all matching files in the input folder"""

        if file_patterns is None:
            file_patterns = ["*.md"]

        all_people = []
        processed_files = []

        for pattern in file_patterns:
            files = list(input_folder.glob(pattern))
            for file_path in sorted(files):
                if file_path.name in [
                    "__init__.py",
                    "tinder.md",
                ]:  # Skip non-data files
                    continue

                try:
                    people = self.process_file(file_path)
                    all_people.extend(people)
                    processed_files.append(file_path.name)

                    print(f"Processed {len(people)} people from {file_path.name}")

                    # Save progress after each file
                    self.save_to_csv(all_people, output_file)

                except Exception as e:
                    print(f"Error processing file {file_path}: {e}")
                    continue

        print(f"\nProcessing complete!")
        print(f"Files processed: {processed_files}")
        print(f"Total people processed: {len(all_people)}")
        print(f"Total API requests made: {self.request_count}")

        return all_people

    def save_to_csv(self, people: List[ProcessedPerson], output_file: Path):
        """Save processed data to CSV"""
        if not people:
            return

        fieldnames = list(ProcessedPerson.__dataclass_fields__.keys())

        with open(output_file, "w", newline="", encoding="utf-8-sig") as csvfile:
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            writer.writeheader()
            for person in people:
                writer.writerow(asdict(person))

        print(f"Data saved to {output_file}")


def main():
    """Main processing function"""
    # Configuration
    API_KEY = "sk-d17e63eeef2d46f4bb404b2a05f125ce"  # Your API key

    # Paths
    input_folder = Path("lib/data_generate_python/raw_data")
    output_file = Path("processed_dating_profiles.csv")

    # Create processor
    processor = DeepSeekProcessor(
        api_key=API_KEY,
        max_requests_per_minute=15,  # Conservative rate limiting
        delay_between_requests=4.0,  # 4 second delay between requests
    )

    # Process files (you can specify which files to process)
    file_patterns = ["men_*.md", "women_*.md"]  # Process all men and women files

    print("Starting data processing with DeepSeek API...")
    print(f"Input folder: {input_folder}")
    print(f"Output file: {output_file}")
    print("=" * 50)

    try:
        all_people = processor.process_all_files(
            input_folder=input_folder,
            output_file=output_file,
            file_patterns=file_patterns,
        )

        print(f"\nFinal results:")
        print(f"Total profiles processed: {len(all_people)}")
        print(f"Output saved to: {output_file}")

    except KeyboardInterrupt:
        print("\nProcessing interrupted by user.")
    except Exception as e:
        print(f"\nUnexpected error: {e}")


if __name__ == "__main__":
    main()
