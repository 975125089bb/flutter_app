import os
import json
import time
import re
import csv
from pathlib import Path
from typing import List, Dict, Any, Optional
from dataclasses import dataclass, asdict
import requests
from datetime import datetime


def normalize_hobbies(hobbies_str: str) -> List[str]:
    """Split and normalize hobbies to avoid redundancy"""
    if not hobbies_str:
        return []

    # Split by common separators
    raw_hobbies = re.split(r"[,Ôºå;Ôºõ„ÄÅ\s]+", hobbies_str)

    # Remove empty strings and duplicates
    unique_hobbies = list(set(hobby.strip() for hobby in raw_hobbies if hobby.strip()))

    # Sort for consistency
    return sorted(unique_hobbies)


@dataclass
class ProcessedPerson:
    """Data structure for processed person information"""

    id: str
    raw_text: Optional[str] = None

    # Basic info
    gender: Optional[str] = None
    birth_year: Optional[str] = None
    age: Optional[int] = None
    zodiac: Optional[str] = None
    mbti: Optional[str] = None

    # Physical attributes
    height_cm: Optional[int] = None
    weight_kg: Optional[int] = None
    bmi: Optional[float] = None

    # Location info
    hometown: Optional[str] = None
    current_location: Optional[str] = None

    # Education & Career
    education: Optional[str] = None
    occupation: Optional[str] = None
    annual_income: Optional[str] = None

    # Lifestyle
    hobbies: Optional[str] = None
    personality: Optional[str] = None

    # Assets & Status
    has_house: Optional[bool] = None
    has_car: Optional[bool] = None
    marital_status: Optional[str] = None

    # Preferences
    partner_preferences: Optional[str] = None
    self_introduction: Optional[str] = None

    def __post_init__(self):
        """Calculate derived fields"""
        if self.height_cm and self.weight_kg:
            height_m = self.height_cm / 100
            self.bmi = round(self.weight_kg / (height_m**2), 1)

        if self.birth_year and self.birth_year.isdigit():
            current_year = datetime.now().year
            birth_year_int = int(self.birth_year)
            if birth_year_int < 100:  # Handle 2-digit years
                birth_year_int += 1900 if birth_year_int > 30 else 2000
            self.age = current_year - birth_year_int

        # Normalize hobbies to avoid redundancy
        if self.hobbies:
            normalized_hobbies = normalize_hobbies(self.hobbies)
            self.hobbies = ", ".join(normalized_hobbies)


class DeepSeekProcessor:
    """Process personal data using DeepSeek API with cost control"""

    def __init__(
        self,
        api_key: str,
        max_requests_per_minute: int = 20,
        delay_between_requests: float = 3.5,
        max_retries: int = 3,
        retry_delay: float = 5.0,
    ):
        self.api_key = api_key
        self.base_url = "https://api.deepseek.com/v1/chat/completions"
        self.max_requests_per_minute = max_requests_per_minute
        self.delay_between_requests = delay_between_requests
        self.max_retries = max_retries
        self.retry_delay = retry_delay
        self.request_count = 0
        self.start_time = time.time()

        self.system_prompt = """
‰Ω†ÊòØ‰∏Ä‰∏™‰∏ì‰∏öÁöÑ‰∏™‰∫∫‰ø°ÊÅØÊèêÂèñÂä©Êâã„ÄÇÁî®Êà∑Â∞ÜÊèê‰æõÂåÖÂê´‰∏™‰∫∫Ê°£Ê°à‰ø°ÊÅØÁöÑ‰∏≠ÊñáÊñáÊú¨„ÄÇ

ËØ∑‰∏•Ê†ºÊåâ‰ª•‰∏ãJSONÊ†ºÂºèËøîÂõûÊèêÂèñÂà∞ÁöÑÊâÄÊúâ‰ø°ÊÅØÔºåÊú™ÊèêÂèäÁöÑÂ≠óÊÆµËøîÂõûnull„ÄÇ
Ê≥®ÊÑèÔºöÊÄßÂà´Â∞ÜÁî±Á≥ªÁªüÊ†πÊçÆÊñá‰ª∂ÂêçËá™Âä®Á°ÆÂÆöÔºåÊó†ÈúÄ‰ªéÊñáÊú¨‰∏≠ÊèêÂèñ„ÄÇ

{
    "birth_year": "Âá∫ÁîüÂπ¥‰ªΩÔºà4‰ΩçÊï∞Â≠óÂ≠óÁ¨¶‰∏≤ÔºåÂ¶Ç'1990'ÔºâÊàñnull",
    "zodiac": "ÊòüÂ∫ßÊàñnull", 
    "mbti": "MBTIÊÄßÊ†ºÁ±ªÂûãÔºà4Â≠óÊØçÔºåÂ¶Ç'ENTJ'ÔºâÊàñnull",
    "height_cm": "Ë∫´È´òÂéòÁ±≥Êï∞ÔºàÊï¥Êï∞ÔºâÊàñnull",
    "weight_kg": "‰ΩìÈáçÂçÉÂÖãÊï∞ÔºàÊï¥Êï∞ÔºâÊàñnull",
    "hometown": "ÂÆ∂‰π°/Âá∫ÁîüÂú∞Êàñnull",
    "current_location": "Áé∞Â±Ö‰ΩèÂú∞/Âú∞Âå∫Êàñnull", 
    "education": "Â≠¶ÂéÜÊàñnull",
    "occupation": "ËÅå‰∏öÊàñnull",
    "annual_income": "Âπ¥Êî∂ÂÖ•ÊèèËø∞Êàñnull",
    "hobbies": "Áà±Â•ΩÂÖ¥Ë∂£ÔºàÂêàÂπ∂‰∏∫‰∏Ä‰∏™Â≠óÁ¨¶‰∏≤ÔºâÊàñnull",
    "personality": "ÊÄßÊ†ºÊèèËø∞Êàñnull",
    "has_house": "ÊòØÂê¶ÊúâÊàøÔºàtrue/false/nullÔºâ",
    "has_car": "ÊòØÂê¶ÊúâËΩ¶Ôºàtrue/false/nullÔºâ",
    "marital_status": "Â©öÂßªÁä∂ÂÜµÊàñnull",
    "partner_preferences": "Êã©ÂÅ∂Ë¶ÅÊ±ÇÊàñnull",
    "self_introduction": "Ëá™Êàë‰ªãÁªçÊàñnull"
}

ÊèêÂèñËßÑÂàôÔºö
1. Âπ¥‰ªΩËΩ¨Êç¢Ôºö81Âπ¥->1981Âπ¥Ôºå04Âπ¥->2004Âπ¥Ôºå2‰ΩçÊï∞Âπ¥‰ªΩÔºö>30Âä†1900Ôºå<=30Âä†2000
2. Âçï‰ΩçËΩ¨Êç¢ÔºöËá™Âä®ËΩ¨Êç¢Ë∫´È´ò‰ΩìÈáçÂà∞ÂéòÁ±≥ÂíåÂçÉÂÖã
3. ÊàøËΩ¶Áä∂ÊÄÅÔºö‰ªé"ÊúâÊàøÊó†ËΩ¶"„ÄÅ"Êó†ÊàøÊúâËΩ¶"Á≠âÊñáÊú¨‰∏≠ÊèêÂèñÂ∏ÉÂ∞îÂÄº
4. ÔºöÂ∞ÜÊâÄÊúâÁà±Â•ΩÂêàÂπ∂‰∏∫‰∏Ä‰∏™Â≠óÁ¨¶‰∏≤ÂêàÂπ∂Áõ∏‰ººÂ≠óÊÆµ
5. Âè™ËøîÂõûJSONÔºå‰∏çË¶ÅÂÖ∂‰ªñÊñáÂ≠óËØ¥Êòé
6. ‰∏çË¶ÅÊèêÂèñÊÄßÂà´‰ø°ÊÅØÔºàÁ≥ªÁªü‰ºöËá™Âä®Â§ÑÁêÜÔºâ

Á§∫‰æãËæìÂÖ•Ôºö"81Âπ¥ÁîüÔºåË∫´È´ò180Ôºå‰ΩìÈáç85ÔºåÊùæÊà∑ÔºåÊ≤àÈò≥ÔºåÂ§ßÂ≠¶ÔºåËΩØ‰ª∂ÔºåÂ§©ËùéÔºåÊúâÊàøÊó†ËΩ¶ÔºåÁ¶ªÂ©öÔºåÁà±Â•ΩÔºö‰π¶Ê≥ïÔºåÊëÑÂΩ±"
Á§∫‰æãËæìÂá∫Ôºö{"birth_year":"1981","zodiac":"Â§©Ëùé","height_cm":180,"weight_kg":85,"hometown":"Ê≤àÈò≥","current_location":"ÊùæÊà∑","education":"Â§ßÂ≠¶","occupation":"ËΩØ‰ª∂","hobbies":"‰π¶Ê≥ïÔºåÊëÑÂΩ±","has_house":true,"has_car":false,"marital_status":"Á¶ªÂ©ö"}
"""

    def rate_limit_control(self):
        """Control API request rate to avoid costs"""
        self.request_count += 1

        # Check if we've exceeded the rate limit
        elapsed_time = time.time() - self.start_time
        if elapsed_time < 60 and self.request_count >= self.max_requests_per_minute:
            sleep_time = 60 - elapsed_time
            print(f"Rate limit reached. Sleeping for {sleep_time:.1f} seconds...")
            time.sleep(sleep_time)
            self.request_count = 0
            self.start_time = time.time()

        # Delay between requests
        time.sleep(self.delay_between_requests)

    def call_api(self, text: str) -> Dict[str, Any]:
        """Make API call with retry logic and rate limiting"""

        for attempt in range(self.max_retries + 1):  # +1 for initial attempt
            try:
                return self._make_api_request(text)
            except requests.exceptions.RequestException as e:
                if attempt < self.max_retries:
                    wait_time = self.retry_delay * (2**attempt)  # Exponential backoff
                    print(
                        f"‚ö†Ô∏è  API request failed (attempt {attempt + 1}/{self.max_retries + 1}): {e}"
                    )
                    print(f"üîÑ Retrying in {wait_time:.1f} seconds...")
                    time.sleep(wait_time)
                else:
                    print(
                        f"‚ùå API request failed after {self.max_retries + 1} attempts: {e}"
                    )
                    return {}
            except Exception as e:
                print(f"‚ùå Unexpected error during API call: {e}")
                return {}

        return {}

    def _make_api_request(self, text: str) -> Dict[str, Any]:
        """Make the actual API request (internal method)"""
        self.rate_limit_control()

        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json",
        }

        payload = {
            "model": "deepseek-chat",
            "messages": [
                {"role": "system", "content": self.system_prompt},
                {"role": "user", "content": text},
            ],
            "temperature": 0.1,  # Low temperature for consistent extraction
            "max_tokens": 1000,
            "stream": False,
        }

        response = requests.post(
            self.base_url, headers=headers, json=payload, timeout=30
        )

        # Handle specific HTTP status codes
        if response.status_code == 429:  # Rate limit exceeded
            print("‚ö†Ô∏è  Rate limit exceeded, waiting longer...")
            time.sleep(self.retry_delay * 2)
            raise requests.exceptions.RequestException("Rate limit exceeded")
        elif response.status_code >= 500:  # Server errors
            raise requests.exceptions.RequestException(
                f"Server error: {response.status_code}"
            )

        response.raise_for_status()

        result = response.json()
        content = result["choices"][0]["message"]["content"].strip()

        # Extract JSON from response
        json_match = re.search(r"\{.*\}", content, re.DOTALL)
        if json_match:
            return json.loads(json_match.group())
        else:
            print(f"‚ö†Ô∏è  No JSON found in response: {content}")
            return {}

    def extract_person_blocks(self, content: str) -> List[Dict[str, str]]:
        """Extract individual person blocks from markdown content"""
        person_blocks = []

        # Split by person entries (ÁºñÂè∑XX pattern)
        pattern = r"ÁºñÂè∑"
        splits = re.split(pattern, content)

        # Process splits in pairs (id, content)
        for i in range(1, len(splits)):
            person_id = i
            person_content = splits[i]
            person_number = None

            if "\n" in person_content:

                # extract the number ID
                first_line = person_content[: person_content.find("\n")]
                match = re.search(r"(\d+)", first_line)
                person_number = match.group(1) if match else "None"

                person_content = (
                    "ÁºñÂè∑"
                    + person_number
                    + "\n"
                    + person_content[person_content.find("\n") + 1 :]
                )

            if person_content:
                person_blocks.append(
                    {"id": person_id, "content": person_content, "Áï™Âè∑": person_number}
                )  # id is assigned by my code, Áï™Âè∑ is assigned by the administrator

        return person_blocks

    def determine_gender_from_filename(self, file_path: Path) -> Optional[str]:
        """Determine gender from filename pattern"""
        filename = file_path.name.lower()
        if filename.startswith("men_"):
            return "Áî∑"
        elif filename.startswith("women_"):
            return "Â•≥"
        return None

    def process_file(self, file_path: Path) -> List[ProcessedPerson]:
        """Process a single data file"""
        print(f"Processing file: {file_path.name}")

        with open(file_path, "r", encoding="utf-8") as f:
            content = f.read()

        person_blocks = self.extract_person_blocks(content)
        processed_people = []

        # Determine gender from filename
        gender_from_filename = self.determine_gender_from_filename(file_path)
        if gender_from_filename:
            print(f"üìã Determined gender from filename: {gender_from_filename}")

        for block in person_blocks:
            person_id = block["id"]
            text = block["content"]

            print(f"Processing person {person_id}...")

            # Call API to extract information
            extracted_info = self.call_api(text)

            if extracted_info:
                # Override gender with filename-based determination
                if gender_from_filename:
                    extracted_info["gender"] = gender_from_filename
                    print(f"‚úì Set gender from filename: {gender_from_filename}")

                # Create ProcessedPerson object
                extracted_info["id"] = person_id
                extracted_info["raw_text"] = text

                try:
                    person = ProcessedPerson(**extracted_info)
                    processed_people.append(person)
                    print(f"‚úì Successfully processed person {person_id}")
                except TypeError as e:
                    print(f"‚úó Error creating person object for {person_id}: {e}")
                    # Create with minimal data
                    person = ProcessedPerson(
                        id=person_id, raw_text=text, gender=gender_from_filename
                    )
                    processed_people.append(person)
            else:
                print(f"‚úó Failed to extract info for person {person_id}")
                # Create with minimal data, but include gender from filename
                person = ProcessedPerson(
                    id=person_id, raw_text=text, gender=gender_from_filename
                )
                processed_people.append(person)

        return processed_people

    def process_all_files(
        self,
        input_folder: Path,
        output_file: Path,
        file_patterns: Optional[List[str]] = None,
    ) -> List[ProcessedPerson]:
        """Process all matching files in the input folder"""

        if file_patterns is None:
            file_patterns = ["*.md"]

        all_people = []
        processed_files = []

        for pattern in file_patterns:
            files = list(input_folder.glob(pattern))
            for file_path in sorted(files):
                if file_path.name in [
                    "__init__.py",
                    "tinder.md",
                ]:  # Skip non-data files
                    continue

                try:
                    people = self.process_file(file_path)
                    all_people.extend(people)
                    processed_files.append(file_path.name)

                    print(f"Processed {len(people)} people from {file_path.name}")

                    # Save progress after each file
                    self.save_to_csv(all_people, output_file)

                except Exception as e:
                    print(f"Error processing file {file_path}: {e}")
                    continue

        print(f"\nProcessing complete!")
        print(f"Files processed: {processed_files}")
        print(f"Total people processed: {len(all_people)}")
        print(f"Total API requests made: {self.request_count}")

        return all_people

    def save_to_csv(self, people: List[ProcessedPerson], output_file: Path):
        """Save processed data to CSV"""
        if not people:
            return

        fieldnames = list(ProcessedPerson.__dataclass_fields__.keys())

        with open(output_file, "w", newline="", encoding="utf-8-sig") as csvfile:
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            writer.writeheader()
            for person in people:
                writer.writerow(asdict(person))

        print(f"Data saved to {output_file}")


def main():
    """Main processing function"""
    # Configuration
    API_KEY = "sk-d17e63eeef2d46f4bb404b2a05f125ce"  # Your API key

    # Paths
    input_folder = Path("lib/data_generate_python/raw_data")
    output_file = Path("processed_dating_profiles.csv")

    # Create processor
    processor = DeepSeekProcessor(
        api_key=API_KEY,
        max_requests_per_minute=15,  # Conservative rate limiting
        delay_between_requests=4.0,  # 4 second delay between requests
    )

    # Process files (you can specify which files to process)
    file_patterns = ["men_*.md", "women_*.md"]  # Process all men and women files

    print("Starting data processing with DeepSeek API...")
    print(f"Input folder: {input_folder}")
    print(f"Output file: {output_file}")
    print("=" * 50)

    try:
        all_people = processor.process_all_files(
            input_folder=input_folder,
            output_file=output_file,
            file_patterns=file_patterns,
        )

        print(f"\nFinal results:")
        print(f"Total profiles processed: {len(all_people)}")
        print(f"Output saved to: {output_file}")

    except KeyboardInterrupt:
        print("\nProcessing interrupted by user.")
    except Exception as e:
        print(f"\nUnexpected error: {e}")


if __name__ == "__main__":
    main()
